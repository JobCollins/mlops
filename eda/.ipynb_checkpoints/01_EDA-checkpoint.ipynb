{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bf6c09",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tcapelle/edu/blob/main/mlops-001/lesson1/01_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{course-lesson1} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212966e-8f38-4b4a-8e00-2985120439ca",
   "metadata": {},
   "source": [
    "# EDA \n",
    "<!--- @wandbcode{course-lesson1} -->\n",
    "\n",
    "In this notebook, we will download a sample of the [BDD100K](https://www.bdd100k.com/) semantic segmentation dataset and use W&B Artifacts and Tables to version and analyze our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17490b58-a8f2-489e-9c71-ca0e078591dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True # set this flag to True to use a small subset of data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50ebcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install wandb\n",
    "!pip install wandb -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d88380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "  Downloading fastai-2.7.10-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pip in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (22.0.3)\n",
      "Requirement already satisfied: packaging in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: requests in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (2.27.1)\n",
      "Requirement already satisfied: matplotlib in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (3.5.1)\n",
      "Requirement already satisfied: scipy in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (1.0.2)\n",
      "Requirement already satisfied: torch<1.14,>=1.7 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (1.10.2)\n",
      "Collecting fastcore<1.6,>=1.4.5\n",
      "  Downloading fastcore-1.5.27-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.8.2 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (0.11.3)\n",
      "Requirement already satisfied: pillow>6.0.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (9.0.1)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pandas in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (1.4.0)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.4.3-cp38-cp38-macosx_10_9_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from spacy<4->fastai) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from spacy<4->fastai) (1.22.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from spacy<4->fastai) (1.9.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp38-cp38-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from spacy<4->fastai) (4.64.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Downloading spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.10.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m888.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp38-cp38-macosx_10_9_x86_64.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 KB\u001b[0m \u001b[31m876.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from spacy<4->fastai) (62.3.2)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp38-cp38-macosx_10_9_x86_64.whl (489 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.5-cp38-cp38-macosx_10_9_x86_64.whl (754 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.4/754.4 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from packaging->fastai) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->fastai) (2.0.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->fastai) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->fastai) (3.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from torch<1.14,>=1.7->fastai) (4.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from matplotlib->fastai) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from matplotlib->fastai) (4.29.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from scikit-learn->fastai) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from scikit-learn->fastai) (1.1.0)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m938.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp38-cp38-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.3-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastai) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jobdulo/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from jinja2->spacy<4->fastai) (2.0.1)\n",
      "Installing collected packages: wasabi, cymem, typer, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, fastprogress, catalogue, blis, srsly, preshed, pathy, fastcore, fastdownload, confection, thinc, spacy, fastai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: fastcore\n",
      "    Found existing installation: fastcore 1.3.29\n",
      "    Uninstalling fastcore-1.3.29:\n",
      "      Successfully uninstalled fastcore-1.3.29\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.3 cymem-2.0.7 fastai-2.7.10 fastcore-1.5.27 fastdownload-0.0.7 fastprogress-1.0.3 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.0 preshed-3.0.8 smart-open-5.2.1 spacy-3.4.3 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.5 thinc-8.1.5 typer-0.7.0 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee88efc-3257-4ed7-bb8c-1695f4a8c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import params\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055764da-7252-4796-86af-585007dea288",
   "metadata": {},
   "source": [
    "We have defined some global configuration parameters in the `params.py` file. `ENTITY` should correspond to your W&B Team name if you work in a team, replace it with `None` if you work individually. \n",
    "\n",
    "In the section below, we will use `untar_data` function from `fastai` to download and unzip our datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae3750-a653-4265-9c52-c1f9af9b8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/wandb_course/bdd_simple_1k.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da50d19-860a-4b39-8320-a376c483da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(untar_data(URL, force_download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5b830-e685-4a0d-81e8-6dda10697dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6708ae-abaa-432f-83b0-028a99222096",
   "metadata": {},
   "source": [
    "Here we define several functions to help us process the data and upload it as a `Table` to W&B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779f980-4d9b-4645-9726-642a25334e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\"\n",
    "\n",
    "def get_classes_per_image(mask_data, class_labels):\n",
    "    unique = list(np.unique(mask_data))\n",
    "    result_dict = {}\n",
    "    for _class in class_labels.keys():\n",
    "        result_dict[class_labels[_class]] = int(_class in unique)\n",
    "    return result_dict\n",
    "\n",
    "def _create_table(image_files, class_labels):\n",
    "    \"Create a table with the dataset\"\n",
    "    labels = [str(class_labels[_lab]) for _lab in list(class_labels)]\n",
    "    table = wandb.Table(columns=[\"File_Name\", \"Images\", \"Split\"] + labels)\n",
    "    \n",
    "    for i, image_file in progress_bar(enumerate(image_files), total=len(image_files)):\n",
    "        image = Image.open(image_file)\n",
    "        mask_data = np.array(Image.open(label_func(image_file)))\n",
    "        class_in_image = get_classes_per_image(mask_data, class_labels)\n",
    "        table.add_data(\n",
    "            str(image_file.name),\n",
    "            wandb.Image(\n",
    "                    image,\n",
    "                    masks={\n",
    "                        \"predictions\": {\n",
    "                            \"mask_data\": mask_data,\n",
    "                            \"class_labels\": class_labels,\n",
    "                        }\n",
    "                    }\n",
    "            ),\n",
    "            \"None\", # we don't have a dataset split yet\n",
    "            *[class_in_image[_lab] for _lab in labels]\n",
    "        )\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac085cd-2409-4baf-a887-108e3dca65b9",
   "metadata": {},
   "source": [
    "We will start a new W&B `run` and put everything into a raw Artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87141b3-b9b7-4a40-839c-64c835484f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"upload\")\n",
    "raw_data_at = wandb.Artifact(params.RAW_DATA_AT, type=\"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de6968-b465-4e2e-aaf1-787a48c7981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at.add_file(path/'LICENSE.txt', name='LICENSE.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10addc71-201d-4c29-af23-9a5d9a5cbddf",
   "metadata": {},
   "source": [
    "Let's add the images and label masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e29a83-ec60-4518-8b73-078f1719bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at.add_dir(path/'images', name='images')\n",
    "raw_data_at.add_dir(path/'labels', name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b989eb-36da-4194-9a34-88126749f210",
   "metadata": {},
   "source": [
    "Let's get the file names of images in our dataset and use the function we defined above to create a W&B Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa2dae-1b2b-4c70-8dcf-b079f4f05b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = get_image_files(path/\"images\", recurse=False)\n",
    "\n",
    "# sample a subset if DEBUG\n",
    "if DEBUG: image_files = image_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ff088-4cb3-4739-b4e8-308d03645ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = _create_table(image_files, params.BDD_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73cd37-6a72-44f7-a5cf-6abe7d327092",
   "metadata": {},
   "source": [
    "Finally, we will add the Table to our Artifact, log it to W&B and finish our `run`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4183e9c-75e4-48a8-a2e1-0f4492c0b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at.add(table, \"eda_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ed9c8-6905-4841-a9f7-e3f3b9b6d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(raw_data_at)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
